{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5769320e-7641-460a-8f3d-fd54f889c24b",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "\n",
    "```yaml\n",
    "course:   DS 5001 \n",
    "topic:    Generating Data Files\n",
    "author:   Andrew Chaphiv (acgq2@virginia.edu)\n",
    "date:    SPR2023\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a3fedc-b905-4256-b1a1-328de75d67d6",
   "metadata": {},
   "source": [
    "# Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "500eef82-bcbc-4ce2-aff2-6fe17a3ecca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import nltk\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d811ccfe-9a1a-4054-a8db-1d738822f936",
   "metadata": {},
   "source": [
    "# Subsetting DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1cbcfa5-6d59-44c5-8842-d8b5d8115e18",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26972/153719802.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# There was a bunch of nonenglish articles present in the initial files, so need to get rid of those\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"condensedabstracts.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mnon_english\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAuthors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\[(Article\\s+in\\s+[A-Za-z-]+)\\]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Some articles are not in english, need to discard.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnon_english\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnon_english\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnon_english\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Authors\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mchinese\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAuthors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[Article in Chinese; Abstract available in Chinese from the publisher]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# There was a bunch of nonenglish articles present in the initial files, so need to get rid of those \n",
    "df = pd.read_csv(\"condensedabstracts.csv\", index_col = 0)\n",
    "non_english = df.Authors.str.match(\"\\[(Article\\s+in\\s+[A-Za-z-]+)\\]\").to_frame() # Some articles are not in english, need to discard.\n",
    "non_english = non_english[non_english[\"Authors\"] == True].index\n",
    "chinese = df.Authors.str.match(\"[Article in Chinese; Abstract available in Chinese from the publisher]\").to_frame()\n",
    "chinese = chinese[chinese[\"Authors\"] == True].index\n",
    "df = df.drop(chinese)\n",
    "chinese = df.Authors.str.find(\"[Article in Chinese; Abstract available in Chinese from the publisher]\").to_frame()\n",
    "chinese = chinese[chinese[\"Authors\"] != -1].index\n",
    "df = df.drop(chinese)\n",
    "df = df.drop(non_english)\n",
    "\n",
    "df = df.reset_index(inplace=False, drop = True)\n",
    "df.index.names = [\"abstract_num\"] \n",
    "\n",
    "df.to_csv(\"abstracts-LIB.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d9771c-6e07-4ae0-aac6-223de71597eb",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7ae9762-e802-4d9c-ae07-57172defe152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>para_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstract_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Interleukin-6 (IL-6) has previously been shown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The goal of screening programmes for cancer is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Non-parametric methods have recently been prop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The observation that charcoal-treated fetal bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A new de-N-acetylated glycosphingolipid termed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9793</th>\n",
       "      <td>OBJECTIVE: To characterize the supportive care...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9794</th>\n",
       "      <td>INTRODUCTION: Outcomes in colorectal cancer tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9795</th>\n",
       "      <td>OBJECTIVES: Chronic thromboembolic pulmonary h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9796</th>\n",
       "      <td>BACKGROUND Robot-assisted radical prostatectom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9797</th>\n",
       "      <td>BACKGROUND Myxofibrosarcoma involving the spin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9798 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       para_str\n",
       "abstract_num                                                   \n",
       "0             Interleukin-6 (IL-6) has previously been shown...\n",
       "1             The goal of screening programmes for cancer is...\n",
       "2             Non-parametric methods have recently been prop...\n",
       "3             The observation that charcoal-treated fetal bo...\n",
       "4             A new de-N-acetylated glycosphingolipid termed...\n",
       "...                                                         ...\n",
       "9793          OBJECTIVE: To characterize the supportive care...\n",
       "9794          INTRODUCTION: Outcomes in colorectal cancer tr...\n",
       "9795          OBJECTIVES: Chronic thromboembolic pulmonary h...\n",
       "9796          BACKGROUND Robot-assisted radical prostatectom...\n",
       "9797          BACKGROUND Myxofibrosarcoma involving the spin...\n",
       "\n",
       "[9798 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAS = df[\"Abstract\"].to_frame('para_str')\n",
    "PARAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2f8c4cc-222f-481e-94b9-d76fc63ed646",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SENTS = PARAS.para_str.apply(lambda x: pd.Series(nltk.sent_tokenize(x)))\\\n",
    "        .stack()\\\n",
    "        .to_frame('sent_str')\n",
    "SENTS.index.names = [\"abstract_num\", \"sent_num\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9aebbaa8-2ef0-4f31-82a8-41735ae0ba54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sent_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstract_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>Interleukin-6 (IL-6) has previously been shown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However, the mechanisms leading to increased I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We have studied the effects of synthetic ceram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The synthetic ceramides C2- and C6-ceramide as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We propose that the sphingomyelin pathway is p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">9797</th>\n",
       "      <th>10</th>\n",
       "      <td>Histopathology identified high-grade myxofibro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Postoperative intensity-modulated radiation th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The patient had greatly improved neurological ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CONCLUSIONS We reported a case of an unresecta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This combination therapy is a relatively safe ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82928 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                sent_str\n",
       "abstract_num sent_num                                                   \n",
       "0            0         Interleukin-6 (IL-6) has previously been shown...\n",
       "             1         However, the mechanisms leading to increased I...\n",
       "             2         We have studied the effects of synthetic ceram...\n",
       "             3         The synthetic ceramides C2- and C6-ceramide as...\n",
       "             4         We propose that the sphingomyelin pathway is p...\n",
       "...                                                                  ...\n",
       "9797         10        Histopathology identified high-grade myxofibro...\n",
       "             11        Postoperative intensity-modulated radiation th...\n",
       "             12        The patient had greatly improved neurological ...\n",
       "             13        CONCLUSIONS We reported a case of an unresecta...\n",
       "             14        This combination therapy is a relatively safe ...\n",
       "\n",
       "[82928 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d955c141-2130-4f66-a012-672b5f732f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS = SENTS.sent_str\\\n",
    "            .apply(lambda x: pd.Series(nltk.pos_tag(nltk.WhitespaceTokenizer().tokenize(x))))\\\n",
    "            .stack()\\\n",
    "            .to_frame('pos_tuple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59241255-2080-4156-b4a1-879a39923868",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS.index.names = [\"abstract_num\", \"sent_num\", \"token_num\"]\n",
    "TOKENS['pos'] = TOKENS.pos_tuple.apply(lambda x: x[1])\n",
    "TOKENS['token_str'] = TOKENS.pos_tuple.apply(lambda x: x[0])\n",
    "TOKENS['term_str'] = TOKENS.token_str.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbb2c721-cea9-48f5-8de5-6ce42864ece5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abstract_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(Interleukin-6, JJ)</td>\n",
       "      <td>JJ</td>\n",
       "      <td>Interleukin-6</td>\n",
       "      <td>interleukin-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>((IL-6), NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>(IL-6)</td>\n",
       "      <td>(il-6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(has, VBZ)</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>has</td>\n",
       "      <td>has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(previously, RB)</td>\n",
       "      <td>RB</td>\n",
       "      <td>previously</td>\n",
       "      <td>previously</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(been, VBN)</td>\n",
       "      <td>VBN</td>\n",
       "      <td>been</td>\n",
       "      <td>been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">9797</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">14</th>\n",
       "      <th>28</th>\n",
       "      <td>(the, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>(size,, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>size,</td>\n",
       "      <td>size,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>(location,, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>location,</td>\n",
       "      <td>location,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(or, CC)</td>\n",
       "      <td>CC</td>\n",
       "      <td>or</td>\n",
       "      <td>or</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>(adhesion., NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>adhesion.</td>\n",
       "      <td>adhesion.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013242 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           pos_tuple  pos      token_str  \\\n",
       "abstract_num sent_num token_num                                            \n",
       "0            0        0          (Interleukin-6, JJ)   JJ  Interleukin-6   \n",
       "                      1                 ((IL-6), NN)   NN         (IL-6)   \n",
       "                      2                   (has, VBZ)  VBZ            has   \n",
       "                      3             (previously, RB)   RB     previously   \n",
       "                      4                  (been, VBN)  VBN           been   \n",
       "...                                              ...  ...            ...   \n",
       "9797         14       28                   (the, DT)   DT            the   \n",
       "                      29                 (size,, NN)   NN          size,   \n",
       "                      30             (location,, NN)   NN      location,   \n",
       "                      31                    (or, CC)   CC             or   \n",
       "                      32             (adhesion., NN)   NN      adhesion.   \n",
       "\n",
       "                                      term_str  \n",
       "abstract_num sent_num token_num                 \n",
       "0            0        0          interleukin-6  \n",
       "                      1                 (il-6)  \n",
       "                      2                    has  \n",
       "                      3             previously  \n",
       "                      4                   been  \n",
       "...                                        ...  \n",
       "9797         14       28                   the  \n",
       "                      29                 size,  \n",
       "                      30             location,  \n",
       "                      31                    or  \n",
       "                      32             adhesion.  \n",
       "\n",
       "[2013242 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKENS = TOKENS[TOKENS.term_str != '']\n",
    "TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbc6cac2-5566-4660-b244-aa38b60b2e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKENS.to_csv(\"abstracts-CORPUS.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9427981-2a24-41dd-954b-23bedbf28cd2",
   "metadata": {},
   "source": [
    "# Generating Vocab Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1969320f-63fc-481f-88bc-7e0590a9361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_words(df, bag = [\"sent_num\"]):\n",
    "    bow = df.groupby(bag+['term_str']).term_str.count().to_frame('n')\n",
    "    return bow\n",
    "\n",
    "def TFIDF(BOW, tf_method = 'sum'):\n",
    "    #sum, max, log, double_norm, raw, binary\n",
    "    DTCM = BOW.n.unstack().fillna(0).astype('int')\n",
    "    if tf_method == 'sum':\n",
    "        TF = DTCM.T / DTCM.T.sum()\n",
    "    elif tf_method == 'max':\n",
    "        TF = DTCM.T / DTCM.T.max()\n",
    "    elif tf_method == 'log':\n",
    "        TF = np.log2(1 + DTCM.T)\n",
    "    elif tf_method == 'raw':\n",
    "        TF = DTCM.T\n",
    "    elif tf_method == 'double_norm':\n",
    "        TF = DTCM.T / DTCM.T.max()\n",
    "    elif tf_method == 'binary':\n",
    "        TF = DTCM.T.astype('bool').astype('int')\n",
    "    TF = TF.T\n",
    "    N = DTCM.shape[0]\n",
    "    DF = DTCM.astype('bool').sum()\n",
    "    IDF = np.log2(N / DF)\n",
    "    TFIDF = TF * IDF\n",
    "    BOW['tf'] = TF.stack()\n",
    "    BOW['tfidf'] = TFIDF.stack()\n",
    "    VOCAB['df'] = DF\n",
    "    VOCAB['idf'] = IDF\n",
    "    return TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73436165-1f25-4ade-8227-a6734fef971b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = TOKENS.term_str.value_counts().to_frame('n')\n",
    "VOCAB.index.name = 'term_str'\n",
    "VOCAB['p'] = VOCAB.n / VOCAB.n.sum()\n",
    "VOCAB['i'] = -np.log2(VOCAB.p)\n",
    "VOCAB['n_chars'] = VOCAB.index.str.len()\n",
    "VOCAB['max_pos'] = TOKENS[['term_str','pos']].value_counts().unstack(fill_value=0).idxmax(1)\n",
    "VOCAB['cat_pos'] = TOKENS[['term_str','pos']].value_counts().to_frame('n').reset_index()\\\n",
    "    .groupby('term_str').pos.apply(lambda x: set(x))\n",
    "sw = pd.DataFrame(nltk.corpus.stopwords.words('english'), columns=['term_str'])\n",
    "sw = sw.reset_index().set_index('term_str')\n",
    "sw.columns = ['dummy']\n",
    "sw.dummy = 1\n",
    "VOCAB['stop'] = VOCAB.index.map(sw.dummy)\n",
    "VOCAB['stop'] = VOCAB['stop'].fillna(0).astype('int')\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer1 = PorterStemmer()\n",
    "VOCAB['stem_porter'] = VOCAB.apply(lambda x: stemmer1.stem(x.name), 1)\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer2 = SnowballStemmer(\"english\")\n",
    "VOCAB['stem_snowball'] = VOCAB.apply(lambda x: stemmer2.stem(x.name), 1)\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer3 = LancasterStemmer()\n",
    "VOCAB['stem_lancaster'] = VOCAB.apply(lambda x: stemmer3.stem(x.name), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a22459b-815f-48e1-99f3-7376c13c96b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow = bag_words(TOKENS)\n",
    "tfidf = TFIDF(bow, tf_method = 'max')\n",
    "VOCAB['tfidf_mean'] = bow.groupby('term_str').tfidf.mean() #TFIDF[TFIDF > 0].mean().fillna(0) # EXPLAIN\n",
    "VOCAB['tfidf_sum'] = tfidf.sum()\n",
    "VOCAB['tfidf_median'] = bow.groupby('term_str').tfidf.median() #TFIDF[TFIDF > 0].median().fillna(0) # EXPLAIN\n",
    "VOCAB['tfidf_max'] = tfidf.max()\n",
    "VOCAB['dfidf'] = VOCAB.df * VOCAB.idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3891cb85-04b4-4745-8caf-17864492e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB.to_csv(\"abstracts-VOCAB.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
